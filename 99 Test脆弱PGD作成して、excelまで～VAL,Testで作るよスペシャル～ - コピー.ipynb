{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.6/dist-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.6/dist-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# [1-2]\n",
    "# 必要なライブラリのインポート\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow with Keras.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "# ART\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの読み込み(通常モデル、耐性モデル)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \"npk4sen-10\"#モデルファイル名\n",
    "\n",
    "Y = \"test脆弱\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"../../models/npk4/\"+X+\".h5\")#Naturalモデルのロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプルの読み込み(通常画像で固定) 読み込むのはVAL用画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_samples: \n",
      "型<class 'numpy.ndarray'>,\n",
      "shape(15684, 30, 30, 3)\n",
      "\n",
      "test_label: \n",
      "型<class 'numpy.ndarray'>,\n",
      "shape(15684, 43)\n",
      "test_samples: \n",
      "型<class 'numpy.ndarray'>,\n",
      "shape(12630, 30, 30, 3)\n",
      "\n",
      "test_label: \n",
      "型<class 'numpy.ndarray'>,\n",
      "shape(12630, 43)\n"
     ]
    }
   ],
   "source": [
    "x_val = np.load('../../input/gtsrb-german-traffic-sign/Instant/x_val.npy')\n",
    "y_val = np.load('../../input/gtsrb-german-traffic-sign/Instant/y_val.npy')\n",
    "\n",
    "x_test = np.load('../../input/gtsrb-german-traffic-sign/Instant/x_test.npy')\n",
    "y_test = np.load('../../input/gtsrb-german-traffic-sign/Instant/y_test.npy')\n",
    "\n",
    "\n",
    "y_val =  to_categorical(y_val, num_classes=43)#評価のためにOne-Hotに\n",
    "#二回実行するとエラーになる\n",
    "y_test =  to_categorical(y_test, num_classes=43)#評価のためにOne-Hotに\n",
    "\n",
    "\n",
    "\n",
    "print(\"test_samples: \\n型{0},\\nshape{1}\".format(type(x_val),x_val.shape,))\n",
    "print(\"\\ntest_label: \\n型{0},\\nshape{1}\".format(type(y_val),y_val.shape,))#整数形式\n",
    "\n",
    "print(\"test_samples: \\n型{0},\\nshape{1}\".format(type(x_test),x_test.shape,))\n",
    "print(\"\\ntest_label: \\n型{0},\\nshape{1}\".format(type(y_test),y_test.shape,))#整数形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルをART Keras Classifierでラップ。\n",
    "# ARTのClassifierインスタンスを作成する（ここではTensorFlowのモデルを想定）\n",
    "\n",
    "classifier = KerasClassifier(model=model, clip_values=(0,1))\n",
    "\n",
    "attack = ProjectedGradientDescent(classifier,eps=(8/255), eps_step=(2/255), max_iter=10, batch_size=64)\n",
    "\n",
    "attack_FGSM = FastGradientMethod(estimator=classifier, eps=(8/255),norm=np.inf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_samples_val = attack.generate(x_val)\n",
    "adv_samples_test = attack.generate(x_test)\n",
    "adv_samples_FGSM = attack_FGSM.generate(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 敵対的サンプルの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    以下評価\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15684/15684 [==============================] - 1s 80us/sample - loss: 0.3600 - accuracy: 0.9264\n",
      "val set accuracy:  92.63580441474915\n",
      "15684/15684 [==============================] - 1s 75us/sample - loss: 1.1184 - accuracy: 0.6226\n",
      "val set accuracy:  62.260901927948\n",
      "12630/12630 [==============================] - 1s 88us/sample - loss: 0.5651 - accuracy: 0.8614\n",
      "val set accuracy:  86.13618612289429\n",
      "12630/12630 [==============================] - 1s 81us/sample - loss: 1.4581 - accuracy: 0.5212\n",
      "val set accuracy:  52.121931314468384\n",
      "12630/12630 [==============================] - 1s 73us/sample - loss: 1.1617 - accuracy: 0.5939\n",
      "val set accuracy:  59.390342235565186\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(x_val, y_val)\n",
    "print('val set accuracy: ', accuracy * 100)\n",
    "N_ac_val = accuracy\n",
    "\n",
    "\n",
    "loss,accuracy = model.evaluate(adv_samples_val, y_val)\n",
    "print('val set accuracy: ', accuracy * 100)\n",
    "AEs_ac_val = accuracy\n",
    "\n",
    "\n",
    "loss,accuracy = model.evaluate(x_test, y_test)\n",
    "print('val set accuracy: ', accuracy * 100)\n",
    "N_ac_test = accuracy\n",
    "\n",
    "\n",
    "loss,accuracy = model.evaluate(adv_samples_test, y_test)\n",
    "print('val set accuracy: ', accuracy * 100)\n",
    "AEs_ac_test = accuracy\n",
    "\n",
    "loss,accuracy = model.evaluate(adv_samples_FGSM, y_test)\n",
    "print('val set accuracy: ', accuracy * 100)\n",
    "AEs_ac_FGSM = accuracy\n",
    "\n",
    "#loss,accuracy = model.evaluate(adv_samples_PGD20, y_test)\n",
    "#print('val set accuracy: ', accuracy * 100)\n",
    "#AEs_ac_PGD20 = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9264\n",
      "0.6226\n",
      "0.8614\n",
      "0.5212\n",
      "0.5939\n"
     ]
    }
   ],
   "source": [
    "print(round(N_ac_val,4))\n",
    "print(round(AEs_ac_val,4))\n",
    "print(round(N_ac_test,4))\n",
    "print(round(AEs_ac_test,4))\n",
    "print(round(AEs_ac_FGSM,4))\n",
    "#print(round(AEs_ac_PGD20,4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像データは0～1の範囲、正解ラベルは元のy_testと変わらないので保存しない\n",
    "#np.save(\"../../input/gtsrb-german-traffic-sign/Instant/\"+X+\".npy\", adv_samples_val)\n",
    "#np.save(\"../../input/gtsrb-german-traffic-sign/Instant/\"+X+\"-test.npy\", adv_samples_test)\n",
    "#np.save(\"../../input/gtsrb-german-traffic-sign/Instant/FGSM/\"+X+\"-test.npy\", adv_samples_FGSM)\n",
    "#np.save(\"../../input/gtsrb-german-traffic-sign/Instant/PGD20/\"+X+\"-test.npy\", adv_samples_PGD20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name = X+\",\"+Y #シートの名前の定義\n",
    "model_name =X\n",
    "sample_name =Y\n",
    "test_samples = adv_samples_test\n",
    "test_labels = np.load('../../input/gtsrb-german-traffic-sign/Instant/y_test.npy')\n",
    "#val_label= np.argmax(val_label,axis = 1) #y_testはOneHot形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_label = []#サンプルのクラスごとの枚数を格納\n",
    "for j in range(43):    \n",
    "    count = 0\n",
    "    for i in range(len(test_labels)):\n",
    "        if test_labels[i] == j:\n",
    "            count +=1\n",
    "    count_label.append(count)\n",
    "moto = []#モデルが間違えた画像の正解ラベルを格納\n",
    "suiron = []#モデルが間違えた画像を何と推論したかを格納\n",
    "wrong_index = []#モデルが推論を間違えているインデックス\n",
    "right_index = []#モデルが正解したインデックス、以下あまり使わない\n",
    "for i in range(len(test_samples)):\n",
    "    Y_hat = model.predict(np.expand_dims(test_samples[i],0))\n",
    "    if test_labels[i] != np.argmax(Y_hat):        \n",
    "        moto.append(test_labels[i])\n",
    "        suiron.append(np.argmax(Y_hat))\n",
    "        wrong_index.append(i)\n",
    "    else:\n",
    "        right_index.append(i)\n",
    "\n",
    "wrong_predict = [] #間違えた画像の分類モデルの推論結果を格納する\n",
    "count_num = []#クラスごとの間違えた数を格納する\n",
    "for j in range(43):    \n",
    "    count = 0\n",
    "    kari_suiron = []\n",
    "    for i in range(len(moto)):\n",
    "        if moto[i] == j:\n",
    "            count +=1\n",
    "            kari_suiron.append(suiron[i])\n",
    "    count_num.append(count)\n",
    "    wrong_predict.append(kari_suiron)\n",
    "\n",
    "wrong_predict_count = []\n",
    "for j in range(43):\n",
    "    count_kari = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(len(wrong_predict[j])):\n",
    "        count_kari[wrong_predict[j][i]] += 1\n",
    "    wrong_predict_count.append(count_kari)\n",
    "#間違えた数/元の枚数で割合を出す\n",
    "wariai = []\n",
    "for i in range(43):\n",
    "    y = count_num[i] / count_label[i]\n",
    "    wariai.append(y)\n",
    "\n",
    "def index_of_second_largest(arr):\n",
    "    sorted_indices = sorted(range(len(arr)), key=lambda i: arr[i], reverse=True)\n",
    "    result = [sorted_indices.index(i) + 1 for i in range(len(arr))]\n",
    "    return result\n",
    "\n",
    "# 例: [8, 9, 2, 4, 7]\n",
    "result = index_of_second_largest(wariai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook(\"../../最終検証.xlsx\")\n",
    "wb.create_sheet(title=sheet_name,index=1)\n",
    "sheet = wb[sheet_name]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sheet[\"A4\"] = model_name\n",
    "\n",
    "sheet['C7'] = 'クラス'\n",
    "for i in range(43):\n",
    "    sheet[\"C\"+str(i+8)]=i\n",
    "\n",
    "sheet['D7'] = '画像の枚数'#count_label\n",
    "sheet['E7'] = '間違えた枚数'#count_num\n",
    "sheet['F7'] = '間違えた割合'#wariai\n",
    "sheet['G7'] = '順位'\n",
    "\n",
    "#クラスごとの間違え先wrong_predict[20]\n",
    "\n",
    "\n",
    "sheet['C7'] = 'クラス'\n",
    "for i in range(43):\n",
    "    sheet[\"C\"+str(i+8)]=i\n",
    "\n",
    "sheet['D7'] = '画像の枚数'#count_label\n",
    "sheet['E7'] = '間違えた枚数'#count_num\n",
    "sheet['F7'] = '間違えた割合'#wariai\n",
    "sheet['G7'] = '順位'\n",
    "\n",
    "for i in range(43):\n",
    "    sheet[\"D\"+str(i+8)]=count_label[i]\n",
    "    sheet[\"E\"+str(i+8)]=count_num[i]\n",
    "    sheet[\"F\"+str(i+8)]=wariai[i]\n",
    "    sheet[\"G\"+str(i+8)]=result[i]\n",
    "\n",
    "sheet[\"L6\"]=\"元クラス\"\n",
    "sheet[\"K7\"]=\"先クラス\"\n",
    "\n",
    "sheet[\"B2\"]=\"val\"\n",
    "sheet[\"G2\"]=\"Test\"\n",
    "sheet[\"B3\"]=\"Natural\"\n",
    "sheet[\"D3\"]=\"AEs\"\n",
    "sheet[\"G3\"]=\"Natural\"\n",
    "sheet[\"I3\"]=\"AEs\"\n",
    "sheet[\"L2\"]=\"FGSM\"\n",
    "sheet[\"L3\"]=\"AEs\"\n",
    "\n",
    "\n",
    "\n",
    "sheet[\"B4\"]= round(N_ac_val,4)\n",
    "sheet[\"D4\"]= round(AEs_ac_val,4)\n",
    "sheet[\"G4\"]= round(N_ac_test,4)\n",
    "sheet[\"I4\"]= round(AEs_ac_test,4)\n",
    "sheet[\"L4\"]= round(AEs_ac_FGSM,4)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(43):\n",
    "    sheet[\"K\"+str(i+8)]=i\n",
    "for i in range(43):\n",
    "    sheet.cell(row=7,column=(12+i)).value=\"クラス\"+str(i)\n",
    "for i in range(43):\n",
    "    for j in range(43):\n",
    "        sheet.cell(row=j+8,column=12+i).value=wrong_predict_count[i][j]\n",
    "wb.save(\"../../最終検証.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <audio autoplay=\"\">\n",
       "        <source src=\"./pointaccent.mp3\"></source>\n",
       "    </audio>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "    <audio autoplay=\"\">\n",
    "        <source src=\"./pointaccent.mp3\"></source>\n",
    "    </audio>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
